{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diya1094/Customer_Churn_Prediction/blob/main/Customer_Churn_Prediciton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_1GOA6z7fBD",
        "outputId": "b95e4113-0de3-4787-9585-2ffb7f452337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing file\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Celebal/WA_Fn-UseC_-Telco-Customer-Churn.csv.xlsx'\n",
        "df = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "-FfB3Bor7scN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"TELCOMMUNICATION CUSTOMER CHURN PREDICTION ANALYSIS\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")"
      ],
      "metadata": {
        "id": "5JisW1Hg8aF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44dec67e-d895-47d3-b7fa-8f32a0d0b902"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=======================================================\n",
            "TELCOMMUNICATION CUSTOMER CHURN PREDICTION ANALYSIS\n",
            "=======================================================\n",
            "Dataset shape: (7043, 21)\n",
            "Columns: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
            "\n",
            "Missing values:\n",
            "customerID          0\n",
            "gender              0\n",
            "SeniorCitizen       0\n",
            "Partner             0\n",
            "Dependents          0\n",
            "tenure              0\n",
            "PhoneService        0\n",
            "MultipleLines       0\n",
            "InternetService     0\n",
            "OnlineSecurity      0\n",
            "OnlineBackup        0\n",
            "DeviceProtection    0\n",
            "TechSupport         0\n",
            "StreamingTV         0\n",
            "StreamingMovies     0\n",
            "Contract            0\n",
            "PaperlessBilling    0\n",
            "PaymentMethod       0\n",
            "MonthlyCharges      0\n",
            "TotalCharges        0\n",
            "Churn               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert TotalCharges to numeric\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Convert binary categorical variables\n",
        "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "df['Churn'] = df['Churn'].astype(str).str.strip().str.lower()\n",
        "print(df['Churn'].unique())\n",
        "df['Churn'] = df['Churn'].map({'yes': 1, 'no': 0})"
      ],
      "metadata": {
        "id": "3kfxDt2lpg7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e4301a-fb3e-41db-ceaf-31cf85529422"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no' 'yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "churn_rate = df['Churn'].mean()\n",
        "print(f\"Overall Churn Rate: {churn_rate:.3f} ({churn_rate*100:.1f}%)\")\n",
        "\n",
        "# Key statistics by churn status\n",
        "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "print(f\"\\nKey Statistics by Churn Status:\")\n",
        "print(df.groupby('Churn')[numeric_cols].mean().round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed8hmyx7HbUz",
        "outputId": "6e44aed8-8c66-47c6-afe9-580a34807647"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Churn Rate: 0.265 (26.5%)\n",
            "\n",
            "Key Statistics by Churn Status:\n",
            "       tenure  MonthlyCharges  TotalCharges\n",
            "Churn                                      \n",
            "0       37.57           61.27       2555.34\n",
            "1       17.98           74.44       1531.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "df_model = df.copy()\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = ['gender','MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                   'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
        "                   'StreamingMovies', 'Contract', 'PaymentMethod']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_model[col] = le.fit_transform(df_model[col])\n",
        "\n",
        "# Create new features\n",
        "df_model['AvgChargePerMonth'] = df_model['TotalCharges'] / (df_model['tenure'] + 1)\n",
        "df_model['IsNewCustomer'] = (df_model['tenure'] <= 12).astype(int)\n",
        "\n",
        "print(f\"Feature engineering completed! Dataset shape: {df_model.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU2ILbk9HlEL",
        "outputId": "73d36c4f-f8ee-42d8-8ae6-1b075428356f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering completed! Dataset shape: (7043, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Drop 'CustomerID' and apply one-hot encoding to categorical features\n",
        "df_model_cleaned = df_model.drop(['customerID'], axis=1)\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df_encoded = pd.get_dummies(df_model_cleaned, drop_first=True)\n",
        "\n",
        "# Now separate features and target\n",
        "X = df_encoded.drop('Churn', axis=1)\n",
        "y = df_encoded['Churn']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
        "\n",
        "# Fill ALL missing values (for numeric and dummy variables)\n",
        "X_train = X_train.fillna(X_train.median(numeric_only=True))\n",
        "X_test = X_test.fillna(X_train.median(numeric_only=True))  # Use training medians\n",
        "\n",
        "# If still any NaNs in dummy columns (rare), replace them with 0\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'AvgChargePerMonth']\n",
        "\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
        "X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "print(\"Training models...\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Use scaled data for Logistic Regression\n",
        "    if name == 'Logistic Regression':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'AUC-ROC': auc_roc,\n",
        "        'Model': model\n",
        "    }\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}, AUC-ROC: {auc_roc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_t60ZSMFdCN",
        "outputId": "9ab7feef-231d-4c75-c229-8197b01d5516"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (5634, 21), Test set: (1409, 21)\n",
            "Training models...\n",
            "\n",
            "Training Logistic Regression...\n",
            "Accuracy: 0.7913, AUC-ROC: 0.8411\n",
            "\n",
            "Training Random Forest...\n",
            "Accuracy: 0.7779, AUC-ROC: 0.8135\n",
            "\n",
            "Training Gradient Boosting...\n",
            "Accuracy: 0.7984, AUC-ROC: 0.8427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparision of model\n",
        "comparison_df = pd.DataFrame(results).T.drop('Model', axis=1)\n",
        "print(comparison_df.round(4))\n",
        "\n",
        "# Find best model based on AUC-ROC\n",
        "best_model_name = comparison_df['AUC-ROC'].idxmax()\n",
        "best_model = results[best_model_name]['Model']\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Best AUC-ROC Score: {comparison_df.loc[best_model_name, 'AUC-ROC']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J60De_Y4JrgI",
        "outputId": "50442134-8bda-469e-a0ea-8e82a8d94cac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Accuracy Precision    Recall  F1-Score   AUC-ROC\n",
            "Logistic Regression  0.791341  0.636986  0.497326  0.558559  0.841078\n",
            "Random Forest        0.777857  0.598071  0.497326  0.543066  0.813545\n",
            "Gradient Boosting    0.798439  0.658451       0.5  0.568389  0.842659\n",
            "\n",
            "Best Model: Gradient Boosting\n",
            "Best AUC-ROC Score: 0.8427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of best model\n",
        "\n",
        "# Make predictions with best model\n",
        "if best_model_name == 'Logistic Regression':\n",
        "    y_pred_best = best_model.predict(X_test_scaled)\n",
        "    y_pred_proba_best = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "else:\n",
        "    y_pred_best = best_model.predict(X_test)\n",
        "    y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion Matrix and Classification Report\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "# Feature Importance (for tree-based models)\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0bg1YkcNQR4",
        "outputId": "0e9256dd-a98b-4782-9ec7-1605c09215cd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[938  97]\n",
            " [187 187]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87      1035\n",
            "           1       0.66      0.50      0.57       374\n",
            "\n",
            "    accuracy                           0.80      1409\n",
            "   macro avg       0.75      0.70      0.72      1409\n",
            "weighted avg       0.79      0.80      0.79      1409\n",
            "\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "              Feature  Importance\n",
            "14           Contract    0.401673\n",
            "4              tenure    0.138284\n",
            "17     MonthlyCharges    0.131861\n",
            "8      OnlineSecurity    0.084067\n",
            "18       TotalCharges    0.072302\n",
            "11        TechSupport    0.056632\n",
            "19  AvgChargePerMonth    0.037753\n",
            "16      PaymentMethod    0.020514\n",
            "7     InternetService    0.017596\n",
            "9        OnlineBackup    0.011292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 15, None],\n",
        "        'min_samples_split': [2, 5]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.05, 0.1, 0.15],\n",
        "        'max_depth': [3, 5]\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'solver': ['liblinear']\n",
        "    }\n",
        "}\n",
        "\n",
        "if best_model_name in param_grids:\n",
        "    print(f\"Tuning hyperparameters for {best_model_name}...\")\n",
        "\n",
        "    if best_model_name == 'Logistic Regression':\n",
        "        X_tune, y_tune = X_train_scaled, y_train\n",
        "    else:\n",
        "        X_tune, y_tune = X_train, y_train\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        models[best_model_name],\n",
        "        param_grids[best_model_name],\n",
        "        cv=5,\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(X_tune, y_tune)\n",
        "\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    best_model_tuned = grid_search.best_estimator_\n",
        "else:\n",
        "    best_model_tuned = best_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdWY_LakNeb8",
        "outputId": "b48611a2-a884-4eac-9d17-d6fa17aba7ae"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning hyperparameters for Gradient Boosting...\n",
            "Best parameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
            "Best cross-validation score: 0.8453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make final predictions\n",
        "if best_model_name == 'Logistic Regression':\n",
        "    y_pred_final = best_model_tuned.predict(X_test_scaled)\n",
        "    y_pred_proba_final = best_model_tuned.predict_proba(X_test_scaled)[:, 1]\n",
        "else:\n",
        "    y_pred_final = best_model_tuned.predict(X_test)\n",
        "    y_pred_proba_final = best_model_tuned.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate final metrics\n",
        "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
        "final_precision = precision_score(y_test, y_pred_final)\n",
        "final_recall = recall_score(y_test, y_pred_final)\n",
        "final_f1 = f1_score(y_test, y_pred_final)\n",
        "final_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
        "\n",
        "print(\"FINAL MODEL PERFORMANCE:\")\n",
        "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"Precision: {final_precision:.4f}\")\n",
        "print(f\"Recall: {final_recall:.4f}\")\n",
        "print(f\"F1-Score: {final_f1:.4f}\")\n",
        "print(f\"AUC-ROC: {final_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qAWFxhNNnoD",
        "outputId": "606c6dfb-af60-4124-d80a-7a8ea02c0a03"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL MODEL PERFORMANCE:\n",
            "Accuracy: 0.7984\n",
            "Precision: 0.6654\n",
            "Recall: 0.4840\n",
            "F1-Score: 0.5604\n",
            "AUC-ROC: 0.8443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Results summary\n",
        "results_summary = {\n",
        "    'best_model': best_model_name,\n",
        "    'final_accuracy': final_accuracy,\n",
        "    'final_precision': final_precision,\n",
        "    'final_recall': final_recall,\n",
        "    'final_f1': final_f1,\n",
        "    'final_auc': final_auc,\n",
        "    'churn_rate': churn_rate\n",
        "}\n",
        "\n",
        "print(f\"\\nRESULTS SUMMARY: {results_summary}\")\n",
        "\n",
        "print(\"\\nFINAL MODEL EVALUATION\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Make final predictions\n",
        "if best_model_name in ['SVM', 'Logistic Regression']:\n",
        "    y_pred_final = best_model_tuned.predict(X_test_scaled)\n",
        "    y_pred_proba_final = best_model_tuned.predict_proba(X_test_scaled)[:, 1]\n",
        "else:\n",
        "    y_pred_final = best_model_tuned.predict(X_test)\n",
        "    y_pred_proba_final = best_model_tuned.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate final metrics\n",
        "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
        "final_precision = precision_score(y_test, y_pred_final)\n",
        "final_recall = recall_score(y_test, y_pred_final)\n",
        "final_f1 = f1_score(y_test, y_pred_final)\n",
        "final_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
        "\n",
        "print(\"FINAL MODEL PERFORMANCE:\")\n",
        "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"Precision: {final_precision:.4f}\")\n",
        "print(f\"Recall: {final_recall:.4f}\")\n",
        "print(f\"F1-Score: {final_f1:.4f}\")\n",
        "print(f\"AUC-ROC: {final_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM5zOpt4mPI9",
        "outputId": "69af86a8-fa59-4047-8a20-8e2449f7b751"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ANALYSIS COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "\n",
            "RESULTS SUMMARY: {'best_model': 'Gradient Boosting', 'final_accuracy': 0.7984386089425124, 'final_precision': 0.6654411764705882, 'final_recall': 0.4839572192513369, 'final_f1': 0.5603715170278638, 'final_auc': np.float64(0.8443152755173216), 'churn_rate': np.float64(0.2653698707936959)}\n",
            "\n",
            "FINAL MODEL EVALUATION\n",
            "------------------------------\n",
            "FINAL MODEL PERFORMANCE:\n",
            "Accuracy: 0.7984\n",
            "Precision: 0.6654\n",
            "Recall: 0.4840\n",
            "F1-Score: 0.5604\n",
            "AUC-ROC: 0.8443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"KEY FINDINGS:\")\n",
        "print(f\"1. Customer churn rate: {churn_rate*100:.1f}%\")\n",
        "\n",
        "if hasattr(best_model_tuned, 'feature_importances_'):\n",
        "    top_features = feature_importance.head(5)['Feature'].tolist()\n",
        "    print(\"2. Top factors influencing churn:\")\n",
        "    for i, feature in enumerate(top_features, 1):\n",
        "        print(f\"   {i}. {feature}\")\n",
        "\n",
        "print(\"\\nBUSINESS RECOMMENDATIONS:\")\n",
        "print(\"1. Focus retention efforts on month-to-month contract customers\")\n",
        "print(\"2. Offer incentives to customers with high monthly charges\")\n",
        "print(\"3. Improve customer experience in first 12 months\")\n",
        "print(\"4. Promote longer-term contracts with discounts\")\n",
        "print(\"5. Target customers with fiber optic internet for retention campaigns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bmc7fsSdJgS",
        "outputId": "d31ae58c-68c3-4af5-a87d-6687b18f5bea"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KEY FINDINGS:\n",
            "1. Customer churn rate: 26.5%\n",
            "2. Top factors influencing churn:\n",
            "   1. Contract\n",
            "   2. tenure\n",
            "   3. MonthlyCharges\n",
            "   4. OnlineSecurity\n",
            "   5. TotalCharges\n",
            "\n",
            "BUSINESS RECOMMENDATIONS:\n",
            "1. Focus retention efforts on month-to-month contract customers\n",
            "2. Offer incentives to customers with high monthly charges\n",
            "3. Improve customer experience in first 12 months\n",
            "4. Promote longer-term contracts with discounts\n",
            "5. Target customers with fiber optic internet for retention campaigns\n"
          ]
        }
      ]
    }
  ]
}